{
  "type": "commonjs",
  "name": "local-ai",
  "displayName": "local_ai",
  "description": "runs a local llm model using ollama",
  "version": "0.0.1",
  "engines": {
    "vscode": "^1.99.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [],
  "main": "./extension.js",
  "contributes": {
    "commands": [
      {
        "command": "local-ai.start",
        "title": "Local AI CHAT"
      },
      {
        "command": "local-ai.helloWorld",
        "title": "helloWorld"
      }
    ]
  },
  "scripts": {
    "lint": "eslint .",
    "pretest": "npm run lint",
    "test": "vscode-test"
  },
  "devDependencies": {
    "@types/mocha": "^10.0.10",
    "@types/node": "20.x",
    "@types/vscode": "^1.99.0",
    "@vscode/test-cli": "^0.0.10",
    "@vscode/test-electron": "^2.4.1",
    "eslint": "^9.23.0"
  },
  "dependencies": {
    "ollama": "^0.5.15"
  }
}
